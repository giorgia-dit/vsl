*** process_ud_data.py ***

... = {fr-ud-, it_isdt-ud-, it_postwita-ud-}

--train "/datasets/...train.conllu" \
--dev "/datasets/...dev.conllu" \
--test "/datasets/...test.conllu" \
--output "{fr,it}_{isdt,pos}_{ud14,ud25}_pproc" \
--labratio 0.2 \
--unlabratio 0.2 \


*** process_twitter_data.py ***

--train "/datasets/oct27.traindev" \
--dev "/datasets/oct27.test" \
--test "/datasets/daily547.conll" \
--output "en_twitter_pproc" \
--ratio 1.0 \


*** vsl_{g,gg}.py ***

--debug 1 \
--model {g,flat,hier} \
--random_seed 0 \
--prefix None \

--data_file {fr,it}_{isdt,pos}_{ud14,ud25}_pproc.ud | en_twitter_pproc. \
--unlabel_file None \
--vocab_file {fr,it}_{isdt,pos}_{ud14,ud25}_vocab | twitter_vocab \
--tag_file {fr_ud14,it_isdt_ud25,it_pos_ud25}_tagfile | twitter_tagfile \
--embed_file {it.bin, fr.bin, twitter_wordvects} \
--use_unlabel {0, 1} \
--prior_file test_{g, gg_flat, gg_hier} \
--embed_type {ud, twitter} \

--embed_dim 100 \
--rnn_type {gru (default), lstm, rnn} \
--tie_weights 1 \

--char_embed_dim 50 (default = 15) \
--char_hidden_size 100 (default = 15) \

--latent_z_size 50 (default = 100) \
--latent_y_size 25 \
--rnn_size 100 \
--mlp_hidden_size 100 \
--mlp_layer 2 \
--latent_x_logvar 1e-3 \

--kl_anneal_rate 1e-4 \
--unlabel_ratio 0.1 \
--update_freq_label 1 \
--update_freq_unlabel 1 \

--opt {adam (default), sgd, rmsprop} \
--n_iter 1000 (default = 30000) \
--batch_size 10 \
--unlabel_batch_size 10 \
--vocab_size 100000 (default = 50000) \
--char_vocab_size 300 \
--train_emb 0 \
--save_prior 1 \
--learning_rate 1e-3 \
--l2 0 \
--grad_clip 10. \
--f1_score 0 \

--print_every 100 \
--eval_every 1000 \
--summarize 1