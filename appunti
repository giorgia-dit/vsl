
### POSTWITA + UNLAB

file = 'it_postwita-ud-'  # {'' (evalita), 'it_isdt-ud-', 'it_postwita-ud-', 'fr-ud-'}
    data_group = 'ud'  # {ud, evalita}
    lab_ratio = 1.0
    unlab_ratio = None

    data_file_path = f"./input/preprocessed/{file}pproc"
    embed_file_path = f"./input/word_vectors_{file}pproc"
    if lab_ratio != 1.0:
        data_file_path += f"_l{str(lab_ratio)[-1]}"
        embed_file_path += f"_l{str(lab_ratio)[-1]}"
    if unlab_ratio:
        data_file_path += f"_ul{str(unlab_ratio)[-1]}"
        embed_file_path += f"_ul{str(unlab_ratio)[-1]}"
    data_file_path += f".{data_group}"
    embed_file_path += f".{data_group}"

    model = 'hier'
    today = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')
    output_dir = 'output_' + today

    args = argparse.Namespace()

    args.batch_size = 10
    args.cdim = 50
    args.char_vocab_size = 300
    args.chsize = 100
    args.data_file = data_file_path
    args.debug = True
    args.edim = 768
    args.embed_file = None # embed_file_path
    args.embed_type = 'bert'
    args.eval_every = 10000 # FIX: 10000 (2)
    args.f1_score = False
    args.grad_clip = 10.0
    args.klr = 0.0001
    args.l2 = 0.0
    args.lr = 0.001
    args.mhsize = 500  # authors value: 100
    args.mlayer = 2
    args.model = f"{model}"
    args.n_iter = 30000  # FIX: 30000 (10)
    args.opt = f"adam"
    args.prefix = None
    args.print_every = 5000 # FIX: 5000 (2)
    args.prior_file = f"./{output_dir}/test_gg_{model}"
    args.random_seed = 0  # {0, 1, 15, 16, 17}
    args.rsize = 500  # authors value: 100
    args.rtype = f"gru"
    args.save_prior = True
    args.summarize = True
    args.tag_file = f"./input/preprocessed/{data_group}_tagfile"
    args.train_emb = False
    args.tw = True
    args.ufl = 1
    args.ufu = 1
    args.unlabel_batch_size = 10
    args.unlabel_file = f"./input/preprocessed/unlabel.twita"  # unlabel.twita / .coris_29 (isdt) / .coris_13 (evalita) / NONE
    args.ur = 0.1
    args.use_cuda = False
    args.use_unlabel = True
    args.vocab_file = f"./{output_dir}/{file}vocab"
    args.vocab_size = 100000
    args.xvar = 0.001
    args.ysize = 100
    args.zsize = 200

    return args


### EVALITA: + UNLAB

    file = ''  # {'' (evalita), 'it_isdt-ud-', 'it_postwita-ud-', 'fr-ud-'}
    data_group = 'evalita'  # {ud, evalita}
    lab_ratio = 1.0
    unlab_ratio = None

    data_file_path = f"./input/preprocessed/{file}pproc"
    embed_file_path = f"./input/word_vectors_{file}pproc"
    if lab_ratio != 1.0:
        data_file_path += f"_l{str(lab_ratio)[-1]}"
        embed_file_path += f"_l{str(lab_ratio)[-1]}"
    if unlab_ratio:
        data_file_path += f"_ul{str(unlab_ratio)[-1]}"
        embed_file_path += f"_ul{str(unlab_ratio)[-1]}"
    data_file_path += f".{data_group}"
    embed_file_path += f".{data_group}"

    model = 'hier'
    today = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')
    output_dir = 'output_' + today

    args = argparse.Namespace()

    args.batch_size = 10
    args.cdim = 50
    args.char_vocab_size = 300
    args.chsize = 100
    args.data_file = data_file_path
    args.debug = True
    args.edim = 768
    args.embed_file = None  # embed_file_path
    args.embed_type = 'bert'
    args.eval_every = 10000  # FIX: 10000 (2)
    args.f1_score = False
    args.grad_clip = 10.0
    args.klr = 0.0001
    args.l2 = 0.0
    args.lr = 0.001
    args.mhsize = 500  # authors value: 100
    args.mlayer = 2
    args.model = f"{model}"
    args.n_iter = 30000  # FIX: 30000 (10)
    args.opt = f"adam"
    args.prefix = None
    args.print_every = 5000  # FIX: 5000 (2)
    args.prior_file = f"./{output_dir}/test_gg_{model}"
    args.random_seed = 0  # {0, 1, 15, 16, 17}
    args.rsize = 500  # authors value: 100
    args.rtype = f"gru"
    args.save_prior = True
    args.summarize = True
    args.tag_file = f"./input/preprocessed/{data_group}_tagfile"
    args.train_emb = False
    args.tw = True
    args.ufl = 1
    args.ufu = 1
    args.unlabel_batch_size = 10
    args.unlabel_file = f"./input/preprocessed/unlabel.coris_13"  # unlabel.twita / .coris_29 (isdt) / .coris_13 (evalita) / NONE
    args.ur = 0.1
    args.use_cuda = False
    args.use_unlabel = True
    args.vocab_file = f"./{output_dir}/{file}vocab"
    args.vocab_size = 100000
    args.xvar = 0.001
    args.ysize = 100
    args.zsize = 200

    return args




# EVALITA 20+80 UR = 0.5

    file = ''  # {'' (evalita), 'it_isdt-ud-', 'it_postwita-ud-', 'fr-ud-'}
    data_group = 'evalita'  # {ud, evalita}
    lab_ratio = 0.2
    unlab_ratio = 0.8

    data_file_path = f"./input/preprocessed/{file}pproc"
    embed_file_path = f"./input/word_vectors_{file}pproc"
    if lab_ratio != 1.0:
        data_file_path += f"_l{str(lab_ratio)[-1]}"
        embed_file_path += f"_l{str(lab_ratio)[-1]}"
    if unlab_ratio:
        data_file_path += f"_ul{str(unlab_ratio)[-1]}"
        embed_file_path += f"_ul{str(unlab_ratio)[-1]}"
    data_file_path += f".{data_group}"
    embed_file_path += f".{data_group}"

    model = 'hier'
    today = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')
    output_dir = 'output_' + today

    args = argparse.Namespace()

    args.batch_size = 10
    args.cdim = 50
    args.char_vocab_size = 300
    args.chsize = 100
    args.data_file = data_file_path
    args.debug = True
    args.edim = 768
    args.embed_file = None  # embed_file_path
    args.embed_type = 'bert'
    args.eval_every = 10000  # FIX: 10000 (2)
    args.f1_score = False
    args.grad_clip = 10.0
    args.klr = 0.0001
    args.l2 = 0.0
    args.lr = 0.001
    args.mhsize = 500  # authors value: 100
    args.mlayer = 2
    args.model = f"{model}"
    args.n_iter = 30000  # FIX: 30000 (10)
    args.opt = f"adam"
    args.prefix = None
    args.print_every = 5000  # FIX: 5000 (2)
    args.prior_file = f"./{output_dir}/test_gg_{model}"
    args.random_seed = 0  # {0, 1, 15, 16, 17}
    args.rsize = 500  # authors value: 100
    args.rtype = f"gru"
    args.save_prior = True
    args.summarize = True
    args.tag_file = f"./input/preprocessed/{data_group}_tagfile"
    args.train_emb = False
    args.tw = True
    args.ufl = 1
    args.ufu = 1
    args.unlabel_batch_size = 10
    args.unlabel_file = None  # unlabel.twita / .coris_29 (isdt) / .coris_13 (evalita) / NONE
    args.ur = 0.5  # default: 0.1
    args.use_cuda = False
    args.use_unlabel = True
    args.vocab_file = f"./{output_dir}/{file}vocab"
    args.vocab_size = 100000
    args.xvar = 0.001
    args.ysize = 100
    args.zsize = 200

    return args

# ISDT 0.2

    file = 'it_isdt-ud-'  # {'' (evalita), 'it_isdt-ud-', 'it_postwita-ud-', 'fr-ud-'}
    data_group = 'ud'  # {ud, evalita}
    lab_ratio = 0.2
    unlab_ratio = None

    data_file_path = f"./input/preprocessed/{file}pproc"
    embed_file_path = f"./input/word_vectors_{file}pproc"
    if lab_ratio != 1.0:
        data_file_path += f"_l{str(lab_ratio)[-1]}"
        embed_file_path += f"_l{str(lab_ratio)[-1]}"
    if unlab_ratio:
        data_file_path += f"_ul{str(unlab_ratio)[-1]}"
        embed_file_path += f"_ul{str(unlab_ratio)[-1]}"
    data_file_path += f".{data_group}"
    embed_file_path += f".{data_group}"

    model = 'hier'
    today = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')
    output_dir = 'output_' + today

    args = argparse.Namespace()

    args.batch_size = 10
    args.cdim = 50
    args.char_vocab_size = 300
    args.chsize = 100
    args.data_file = data_file_path
    args.debug = True
    args.edim = 768
    args.embed_file = None  # embed_file_path
    args.embed_type = 'bert'
    args.eval_every = 10000  # FIX: 10000 (2)
    args.f1_score = False
    args.grad_clip = 10.0
    args.klr = 0.0001
    args.l2 = 0.0
    args.lr = 0.001
    args.mhsize = 500  # authors value: 100
    args.mlayer = 2
    args.model = f"{model}"
    args.n_iter = 30000  # FIX: 30000 (10)
    args.opt = f"adam"
    args.prefix = None
    args.print_every = 5000  # FIX: 5000 (2)
    args.prior_file = f"./{output_dir}/test_gg_{model}"
    args.random_seed = 0  # {0, 1, 15, 16, 17}
    args.rsize = 500  # authors value: 100
    args.rtype = f"gru"
    args.save_prior = True
    args.summarize = True
    args.tag_file = f"./input/preprocessed/{data_group}_tagfile"
    args.train_emb = False
    args.tw = True
    args.ufl = 1
    args.ufu = 1
    args.unlabel_batch_size = 10
    args.unlabel_file = None  # unlabel.twita / .coris_29 (isdt) / .coris_13 (evalita) / NONE
    args.ur = 0.5  # default: 0.1
    args.use_cuda = False
    args.use_unlabel = False
    args.vocab_file = f"./{output_dir}/{file}vocab"
    args.vocab_size = 100000
    args.xvar = 0.001
    args.ysize = 100
    args.zsize = 200

    return args